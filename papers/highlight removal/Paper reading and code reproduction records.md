# Paper reading and code reproduction records--highlight removal

----

[TOC]



## 0.CVPR 2022 无监督去雾--Self-augmented Unpaired Image Dehazing via Density and Depth Decomposition



### 现有缺点：

​		现有合成数据集在训练中存在**过拟合**问题

​		由此最近的一些方法就通过训练非配对的数据来提高模型的泛化能力(cyclegan -- A域->B域)；但大都是简单的指定加入去雾&加雾，而忽略了现实世界雾霾环境的物理特性，即雾霾随密度和深度的变化而变化。

>​		**<u>CycleGAN 是一个被广泛采用的用于非配对图像到图像转换的框架</u>**。一方面，利用 GAN 损失来加强图像在两个域之间的转换。另一方面，周期重构损失很好地维持了内容的一致性。对于图像去雾，基于 cyclegan 的方法通常包含去雾网络和加雾网络，分别从对应的预测干净图像和雾图像。
>
>​		本文认为这种做法可能是有问题的。在这些方法中忽略了两个关键性质，**深度**和**密度**。因此，生成的雾霾通常缺乏真实感和多样性，这进一步影响了去雾网络的学习。
>
>​		为了解决这些问题，提出了一种新的非配对去雾框架，称为 D4 (通过将传输图分解为密度和深度去雾)。

​	



### 本文核心思想



本文提出了一种自增强的图像去雾框架，称为 D4 (Dehazing via Decomposition, transmission map into Density and Depth)，用于**生成和去除雾霾**。该框架不只是估计传输图或干净的内容，而是专注于探索模糊和干净图像中包含的散射系数和深度信息。在估计场景深度的情况下，本文的方法能够重新渲染不同厚度的模糊图像，这进一步有利于去雾网络的训练。值得注意的是，整个训练过程只需要不配对的**模糊**图像和**干净**的图像，但成功地从单一的模糊图像中恢复散射系数、深度图和干净内容。

![image-20221101144720159](assets/image-20221101144720159.png)




